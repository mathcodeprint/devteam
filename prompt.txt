# Project Overview

This project is a multi-agent system designed to collaboratively develop and test a "Hello World" application ( and other progeams ). It utilizes a Tkinter-based GUI for interaction and management, and can leverage both online LLMs (via API keys) and local LLMs (via Ollama).

## Directory Structure
.
├── agents/
│ ├── init.py
│ ├── base.py
│ ├── developer.py
│ ├── manager.py
│ └── tester.py
├── base.py
├── chatgpt_suite/
│ ├── bin/
│ ├── include/
│ ├── lib/
│ └── share/
├── config/
│ ├── agents.json
│ ├── llm_settings.json
│ └── tasks.json
├── devteam.tar
├── gui.py
├── main.py
├── project/
│ ├── comms/
│ │ ├── msg_Dev1_Dev1.json
│ │ ├── msg_Dev1_Dev2.json
│ │ ├── msg_Dev2_Dev2.json
│ │ └── processed/
│ │ ├── msg_Dev1_Dev1.json
│ │ ├── msg_Dev1_Dev2.json
│ │ ├── msg_Dev1_Manager1.json
│ │ ├── msg_Dev1_ProjectOrchestrator.json
│ │ ├── msg_Dev2_Dev1.json
│ │ ├── msg_Dev2_Dev2.json
│ │ ├── msg_Dev2_Manager1.json
│ │ ├── msg_Dev2_ProjectOrchestrator.json
│ │ ├── msg_Tester1_Dev1.json
│ │ ├── msg_Tester1_Dev2.json
│ │ └── msg_Tester1_ProjectOrchestrator.json
│ ├── progress_report.txt
│ ├── src/
│ └── tests/
├── requirements.txt
├── setup_local_qwen.sh
└── setup.sh


## Key Files and Their Roles

*   `main.py`: The entry point of the application. It orchestrates the overall flow, initializes the GUI, and manages the agents. It passes LLM provider settings and API keys to the agent system.
*   `gui.py`: Implements the Tkinter-based graphical user interface. It allows users to select LLM providers, enter API keys, install local LLMs, and start/stop the agent system. It persists LLM settings to `config/llm_settings.json`.
*   `agents/`: This directory contains the definitions for different types of agents.
    *   `agents/base.py`: Defines the base `Agent` class and common functionalities like calling local LLM models.
    *   `agents/developer.py`: Defines the `DeveloperAgent` responsible for generating code. It includes logic to filter out non-code output from LLMs.
    *   `agents/manager.py`: Defines the `ManagerAgent` (ProjectOrchestrator) responsible for task assignment and progress monitoring.
    *   `agents/tester.py`: Defines the `TesterAgent` responsible for testing generated code. It is designed to accept arbitrary keyword arguments (`**kwargs`) to ignore unexpected parameters.
*   `config/`: This directory stores configuration files.
    *   `config/agents.json`: Defines the different agents in the system, their roles, skills, and descriptions.
    *   `config/tasks.json`: Defines the tasks for the agents to perform, including descriptions, types (e.g., "code", "test"), function names, and expected return values/outputs.
    *   `config/llm_settings.json`: (Created dynamically) Stores the last selected LLM provider and API key for persistence across restarts.
*   `project/`: This directory seems to be where the agents interact and store their work.
    *   `project/comms/`: Contains communication logs between agents.
    *   `project/src/`: Expected to hold the source code generated by developer agents.
    *   `project/tests/`: Expected to hold test scripts generated by tester agents.
*   `requirements.txt`: Lists the Python dependencies required for the project.
*   `setup_local_qwen.sh`: A shell script for setting up a local Qwen LLM.
*   `setup.sh`: A general setup script for the project.

## Configuration File Details

### `config/agents.json`
```json
{
  "agents": [
    {
      "type": "manager",
      "name": "ProjectOrchestrator",
      "role": "Project Coordinator",
      "skills": ["task_assignment", "progress_monitoring", "integration_supervision"],
      "description": "Coordinates developer and testing agents to build a Hello World application using a local AI model for code generation and testing."
    },
    {
      "type": "developer",
      "name": "Dev1",
      "role": "Hello Developer",
      "skills": ["python", "function_development"],
      "specialization": "Hello component",
      "description": "Uses a local AI model to develop the 'Hello' function for the Hello World app."
    },
    {
      "type": "developer",
      "name": "Dev2",
      "role": "World Developer",
      "skills": ["python", "function_development"],
      "specialization": "World component",
      "description": "Uses a local AI model to develop the 'World' function for the Hello World app."
    },
    {
      "type": "tester",
      "name": "Tester1",
      "role": "QA Engineer",
      "skills": ["testing", "execution"],
      "description": "Tests the Hello World app by generating and running a test script with a local AI model to verify the combined output."
    }
  ]
}
```

### `config/tasks.json`
```json
{"tasks": [{"id": 1, "description": "Implement Hello function", "type": "code", "function_name": "hello", "return_value": "Hello"}, {"id": 2, "description": "Implement World function", "type": "code", "function_name": "world", "return_value": "World"}, {"id": 3, "description": "Test Hello World output", "type": "test", "test_spec": {"combination": "print(hello() + ' ' + world())", "expected_output": "Hello World"}}]}
```

### `config/llm_settings.json` (Example, content will vary based on user settings)
```json
{
  "llm_provider": "Ollama (Local)",
  "api_key": "YOUR_REPLICATE_API_KEY",
  "local_llm_model": "Code Llama 7B"
}
```
*Note: This file is created and updated dynamically by the `gui.py` based on user interactions.*

## Current Functionality

The application allows users to:
*   Select between online and local LLM providers.
*   Enter and persist API keys for online LLMs (specifically Replicate).
*   Install local LLM models (e.g., "Code Llama 7B") using `ollama pull`.
*   Run a multi-agent system where a manager orchestrates developer and tester agents to complete tasks defined in `config/tasks.json`.
*   Developer agents focus on generating code, while tester agents generate and run tests.
*   The system handles communication between agents and logs progress.

## Future Enhancements/Considerations

*   **Error Handling and Robustness:** Improve error handling for LLM API calls and local LLM interactions.
*   **More LLM Providers:** Extend support to other online and local LLM providers beyond Replicate and Ollama.
*   **Task Management UI:** Enhance the GUI to provide better visualization and management of tasks.
*   **Code Quality and Linting:** Integrate code quality checks and linting tools into the developer agent's workflow.
*   **Scalability:** Consider how the system scales with more complex tasks and a larger number of agents.
*   **Security:** Implement best practices for API key management and securing local LLM deployments.
*   **Dynamic Task Generation:** Potentially allow the manager agent to dynamically generate tasks rather than relying solely on `tasks.json`.
